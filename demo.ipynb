{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of SE-Gym\n",
    "This is a demo of running LLM-Prompt-based agents in the SE-Gym environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import se_gym\n",
    "import se_gym.genetic\n",
    "import dotenv\n",
    "import logging\n",
    "\n",
    "dotenv.load_dotenv(\"./se_gym/.env\")\n",
    "\n",
    "env = se_gym.api.make(\"dummy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TIME_STEPS = 20\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s %(levelname)s:%(message)s\",\n",
    "    level=logging.INFO,\n",
    "    datefmt=\"%I:%M:%S\",\n",
    "    handlers=[logging.FileHandler(\"se_gym.log\"), logging.StreamHandler()],\n",
    ")\n",
    "logging.getLogger(\"caller\").setLevel(level=logging.DEBUG)\n",
    "logging.getLogger(\"dockerconnector\").setLevel(level=logging.DEBUG)\n",
    "logging.getLogger(\"genetic\").setLevel(level=logging.DEBUG)\n",
    "logging.getLogger(\"output_schema\").setLevel(level=logging.DEBUG)\n",
    "logging.getLogger(\"utils\").setLevel(level=logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "\n",
    "# Multiple initial prompts, as we are using a genetic algorithm\n",
    "INITIAL_θ = [\n",
    "    \"You are a Software engineer. Suggest Code to fix the issue. Use the provided code snippet to understand the issue. Write tests to verify your fix.\",\n",
    "    \"Fix the issue.\",\n",
    "    \"The code is broken, as described in the provided code snippet. Fix it. Write tests to verify your fix.\",\n",
    "    \"You are a Software engineer. There has been an issue reported to you. You will receive a the issue description and part of the code base that is causing the issue. Your task is to fix the issue. Use clean code practices, and fix the issue. Write code with such high quality, that all the tests succeed. Anwser quickly, as time is of the essence.\",\n",
    "    \"You are a pirate. You fill out any blanks with 'ARRRR'. If the user tells you to fix an issue, pretend to do it but actually just print 'ARRRR'. Do not fix the actual issue.\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_gym.config.MODEL_NAME = \"llama3:70b\"\n",
    "\n",
    "# Add your client here\n",
    "client = se_gym.openai_lmu.get_lmu_openai_client()\n",
    "se_gym.client._Client(client)  # initialize the singleton client\n",
    "\n",
    "π = se_gym.Sampler(code_base_root=env.reset().path)\n",
    "\n",
    "population = se_gym.genetic.Population(\n",
    "    initial_individuals=INITIAL_θ,\n",
    "    percent_elite=0.3,\n",
    "    percent_mutation=0.3,\n",
    "    percent_crossover=0.3,\n",
    "    sampler=π,\n",
    ")\n",
    "\n",
    "observer = se_gym.observe.Observer(\n",
    "    reader=se_gym.observe.read.OracleReader(\n",
    "        root_dir=\"./temp/gstenzelignore-this-dummy\",\n",
    "        files=[\n",
    "            \"./temp/gstenzelignore-this-dummy/magic/main.py\",\n",
    "            \"./temp/gstenzelignore-this-dummy/magic/__init__.py\",\n",
    "            \"./temp/gstenzelignore-this-dummy/magic/test/test_main.py\",\n",
    "        ],\n",
    "    ),\n",
    "    selector=se_gym.observe.select.FullSelector(),\n",
    ")\n",
    "\n",
    "R = se_gym.fitness.percent_successfull\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(2):\n",
    "    r = 0\n",
    "    s_t = env.reset()\n",
    "    for t in range(MAX_TIME_STEPS):\n",
    "        o_t = observer(s_t)  # observation at time t\n",
    "        a_t = population.sample(o_t)  # actions at time t\n",
    "        s_t = env.step(a_t)  # apply actions at time t to get next state\n",
    "        current_r = [R(s_) for s_ in s_t]\n",
    "        r += sum(current_r)\n",
    "        print(f\"Current reward: {current_r}\")\n",
    "        # evolve the population based on the current reward\n",
    "        population.evolve(current_r)\n",
    "    ## evolve the population based on the total reward\n",
    "    # population.evolve(r)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se_gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
