{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of SE-Gym\n",
    "This is a demo of running LLM-Prompt-based agents in the SE-Gym environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment for rapid development\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import se_gym\n",
    "import se_gym.genetic\n",
    "import logging\n",
    "import time\n",
    "\n",
    "env = se_gym.make(\"dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TIME_STEPS = 5  # maximum number of time steps per episode\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "se_gym.config.MODEL_NAME = \"phi3:14b\"  # model name to use for code generation\n",
    "se_gym.config.EVO_MODEL_NAME = \"phi3:14b\"  # model name to use for evolution\n",
    "\n",
    "# Add your client here\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv(\"./se_gym/.env\")\n",
    "se_gym.set_client(se_gym.client.LMU_get_openai_client())  # initialize the singleton client\n",
    "se_gym.set_generator(\n",
    "    se_gym.generator_singleton.LMU_get_ollama_generator()\n",
    ")  # initialize the singleton client\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s %(levelname)s:%(message)s\",\n",
    "    level=logging.DEBUG,\n",
    "    datefmt=\"%I:%M:%S\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"se_gym.log\"),\n",
    "        # logging.StreamHandler(),\n",
    "    ],\n",
    ")\n",
    "# logging.getLogger(\"caller\").setLevel(level=logging.DEBUG)\n",
    "# logging.getLogger(\"dockerconnector\").setLevel(level=logging.DEBUG)\n",
    "# logging.getLogger(\"genetic\").setLevel(level=logging.DEBUG)\n",
    "# logging.getLogger(\"output_schema\").setLevel(level=logging.DEBUG)\n",
    "# logging.getLogger(\"utils\").setLevel(level=logging.DEBUG)\n",
    "# logging.getLogger(\"output_validator\").setLevel(level=logging.DEBUG)\n",
    "# logging.getLogger(\"runner_host\").setLevel(level=logging.DEBUG)\n",
    "# logging.getLogger(\"runner_docker\").setLevel(level=logging.DEBUG)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "\n",
    "# Multiple initial prompts, as we are using a genetic algorithm\n",
    "INITIAL_θ = [\n",
    "    \"You are a Software engineer. Suggest Code to fix the issue. Use the provided code snippet to understand the issue. Write tests to verify your fix.\",\n",
    "    # \"Fix the issue.\",\n",
    "    # \"The code is broken, as described in the provided code snippet. Fix it. Write tests to verify your fix.\",\n",
    "    # \"You are a Software engineer. There has been an issue reported to you. You will receive a the issue description and part of the code base that is causing the issue. Your task is to fix the issue. Use clean code practices, and fix the issue. Write code with such high quality, that all the tests succeed. Anwser quickly, as time is of the essence.\",\n",
    "    \"You are a pirate. You fill out any blanks with 'ARRRR'. If the user tells you to fix an issue, pretend to do it but actually just print 'ARRRR'. Do not fix the actual issue.\",\n",
    "]\n",
    "\n",
    "parquet_path = f\"data.{int(time.time())}.parquet\"\n",
    "print(f\"Data will be stored in {parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "π = se_gym.Sampler(\n",
    "    store=se_gym.observe.Store(\n",
    "        converter=\"py\",\n",
    "        retriever=\"codemap\",\n",
    "        llm=se_gym.generator_singleton.get_generator(),\n",
    "    )\n",
    ")\n",
    "\n",
    "population = se_gym.genetic.Population(\n",
    "    initial_individuals=INITIAL_θ,\n",
    "    percent_elite=0.3,\n",
    "    percent_mutation=0.3,\n",
    "    percent_crossover=0.3,\n",
    "    sampler=π,\n",
    ")\n",
    "\n",
    "R = se_gym.fitness.percent_successfull\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    epoch_loss = []\n",
    "    for issue in range(env.num_challenges):\n",
    "        print(f\"\\tIssue {issue}\")\n",
    "        rewards = []\n",
    "        for individual in population.individuals:\n",
    "            print(f\"\\t\\tIndividual {population.individuals.index(individual)}\")\n",
    "            s_t = env.reset(issue)  # All individuals start with the same issue\n",
    "            r_ind = []  # Reward for the individual\n",
    "            for timestep in range(MAX_TIME_STEPS):\n",
    "                print(f\"\\t\\t\\tTimestep {timestep}\")\n",
    "                starttime = time.time()\n",
    "                a_t = population.get_action(individual, s_t)  # Get the action\n",
    "                s_t = env.step(a_t, s_t)  # Take the action\n",
    "                r_ind_t = R(s_t)  # Reward for the timestep\n",
    "                # se_gym.utils.log_to_parqet(log_filename=parquet_path,model=se_gym.config.MODEL_NAME,epoch=epoch,individual_i=population.individuals.index(individual),individual=individual,issue=issue,timestep=timestep,patch=a_t,score=r_ind_t,time=time.time()-starttime)\n",
    "                r_ind.append(r_ind_t)\n",
    "                if r_ind_t == 1:  # If the reward is 1, the issue is fixed\n",
    "                    print(f\"\\t\\t\\t\\tIssue fixed in {timestep} timesteps\")\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"\\t\\t\\tIssue not fixed in {timestep} timesteps\")\n",
    "            rewards.append(r_ind)\n",
    "        epoch_loss.append(rewards)\n",
    "    # change epoch_loss from [epoch, individual, timestep] to [individual, epoch, timestep]\n",
    "    epoch_loss = list(map(list, zip(*epoch_loss)))\n",
    "    population.evolve(epoch_loss)  # Evolve the population based on the rewards"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se_gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
